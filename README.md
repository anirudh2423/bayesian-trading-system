# Bayesian Multi-Armed Bandit Trading System

An intelligent trading system that uses **Thompson Sampling** to dynamically select between competing trading strategies while minimizing Bayesian regret.

![Dashboard](bayesian_trading_dashboard.png)

## ğŸ¯ What It Does

This system treats strategy selection as a **multi-armed bandit problem**:
- **Arms**: Momentum, Mean Reversion, Trend Following strategies
- **Reward**: Trading performance in [0, 1] range
- **Goal**: Maximize cumulative reward while minimizing regret

Thompson Sampling uses **Beta-distributed priors** that update with each observation, naturally balancing exploration vs. exploitation.

## ğŸ“Š Results on SPY (5 Years)

| Metric | Value |
|--------|-------|
| Regret Ratio | 23.44% of theoretical bound |
| Efficiency | 86.4% vs Oracle (perfect hindsight) |
| Sublinear Growth | âœ“ Confirmed |
| Rounds | 1,155 trading days |

## ğŸ–¼ï¸ Visualizations

### 1. Regret vs Theoretical Bound
![Regret](01_regret_analysis.png)
Cumulative regret stays well below O(âˆš(KÂ·TÂ·log(T))) bound.

### 2. Posterior Evolution
![Posteriors](04_posterior_evolution.png)
Beta distributions sharpen as evidence accumulates.

### 3. Selection Heatmap
![Heatmap](03_selection_heatmap.png)
Exploration â†’ exploitation transition over time.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Run simulation
python main.py
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ main.py              # Main simulation orchestrator
â”œâ”€â”€ thompson_sampling.py # Thompson Sampling engine (Beta priors)
â”œâ”€â”€ strategies.py        # Trading strategies + Oracle baseline
â”œâ”€â”€ market_data.py       # SPY data fetcher + regime detection
â”œâ”€â”€ regret.py            # Regret calculation with bounds
â”œâ”€â”€ visualizations.py    # 5 matplotlib visualizations
â””â”€â”€ requirements.txt     # Python dependencies
```

## ğŸ§  How It Works

### Thompson Sampling Algorithm
1. Initialize Beta(Î±=1, Î²=1) prior for each strategy (uniform)
2. Sample from each posterior: `Î¸ ~ Beta(Î±, Î²)`
3. Select strategy with highest sample
4. Execute trade, observe reward `r âˆˆ [0, 1]`
5. Update: `Î± += r`, `Î² += (1 - r)`
6. Repeat

### Trading Strategies
- **Momentum**: Buy winners, sell losers (best in Bull/Bear)
- **Mean Reversion**: Buy oversold, sell overbought (best in Ranging)
- **Trend Following**: Follow moving average crossovers

### Market Regimes
Detected from price data using:
- 20-day momentum
- 20-day volatility
- SMA crossovers

Classifications: BULL, BEAR, RANGING, VOLATILE

## ğŸ“ˆ Theoretical Background

Thompson Sampling achieves **O(âˆš(KÂ·TÂ·log(T)))** regret where:
- K = number of arms (strategies)
- T = number of rounds

This is **near-optimal** for stochastic bandits.

## ğŸ› ï¸ Configuration

Edit `main.py` to customize:
```python
sim = BayesianTradingSimulation(
    years=5,        # Years of SPY data
    start_idx=50    # Skip first N days for indicator warmup
)
sim.visualize(show=True)  # Set True for interactive display
```

## ğŸ“ License

MIT License
